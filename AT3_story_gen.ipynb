{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**A story of 100 words about the prompt**"
      ],
      "metadata": {
        "id": "rfCWe_1UcRLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Interacting with Azure OpenAI Service"
      ],
      "metadata": {
        "id": "ULY5_DRWYmeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJvONxK-XSzU",
        "outputId": "f2b6cda3-0ac6-49b7-996d-8de2d25dcff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.23.4)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "Successfully installed openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "V3pI9coLlPga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from openai import AsyncAzureOpenAI"
      ],
      "metadata": {
        "id": "wCQ6yjJ-YoqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to True to print the full response from OpenAI for each call\n",
        "printFullResponse = True\n",
        "\n",
        "async def call_openai_model(prompt, model, client):\n",
        "    # Provide a basic user message, and use the prompt content as the user message\n",
        "    system_message = \"You are a helpful AI assistant that helps Book Authors write story.\"\n",
        "    user_message = prompt\n",
        "\n",
        "    # Format and send the request to the model\n",
        "    messages =[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    # Call the Azure OpenAI model\n",
        "    response = await client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    # Print the response to the console, if desired\n",
        "    if printFullResponse:\n",
        "        print(response.choices[0].message.content)\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "TnN2I8htYsSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "  try:\n",
        "        # Get configuration settings\n",
        "        # Configuration settings\n",
        "        azure_oai_endpoint =\"\"\n",
        "        azure_oai_key =\"\"\n",
        "        azure_oai_deployment =\"\"\n",
        "\n",
        "        # Configure the Azure OpenAI clients\n",
        "        client = AsyncAzureOpenAI(\n",
        "            azure_endpoint = azure_oai_endpoint,\n",
        "            api_key=azure_oai_key,\n",
        "            api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            user_input = input('Message AzureOpenAI Service or Type \"quit\" to exit: ')\n",
        "            if user_input.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            prompt = user_input\n",
        "            response = await call_openai_model(prompt, model=azure_oai_deployment, client=client)\n",
        "\n",
        "        # Write the response to a file\n",
        "        print(\"\\nHere's your Story:\\n\\n\", response.choices[0].message.content)\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "  except Exception as ex:\n",
        "        print(ex)\n"
      ],
      "metadata": {
        "id": "R8Ir_yceZRK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function in the event loop\n",
        "# Write a story about Desi indian fictional super hero. The story should be limited only to 100 words. Be extra creative and humorous.\n",
        "story = await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nzed3xLZqq_",
        "outputId": "96717f93-43a3-4e10-cbeb-c1a279cb69b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message AzureOpenAI Service or Type \"quit\" to exit: Write a story about Desi indian fictional super hero. The story should be limited only to 100 words. Be extra creative and humorous.\n",
            "In the bustling streets of Mumbai, a timid software engineer named Raj stumbled upon a mystical samosa. One bite transformed him into \"The Curry Crusader,\" a Desi superhero with extraordinary powers. With his trusty sidekick, Butter Naan, they fought crime with a dash of humor. The duo once foiled a bank robbery by distracting the thieves with a Bollywood dance-off. Another time, they used Raj's spicy breath to defeat an evil villain. From saving chaat stalls to rescuing lost wedding rings, The Curry Crusader and Butter Naan spiced up Mumbai's crime-fighting scene one masala-filled adventure at a time.\n",
            "Message AzureOpenAI Service or Type \"quit\" to exit: quit\n",
            "\n",
            "Here's your Story:\n",
            "\n",
            " In the bustling streets of Mumbai, a timid software engineer named Raj stumbled upon a mystical samosa. One bite transformed him into \"The Curry Crusader,\" a Desi superhero with extraordinary powers. With his trusty sidekick, Butter Naan, they fought crime with a dash of humor. The duo once foiled a bank robbery by distracting the thieves with a Bollywood dance-off. Another time, they used Raj's spicy breath to defeat an evil villain. From saving chaat stalls to rescuing lost wedding rings, The Curry Crusader and Butter Naan spiced up Mumbai's crime-fighting scene one masala-filled adventure at a time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Story in Embedding/vector Format**"
      ],
      "metadata": {
        "id": "cTqt7HK7cPY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "2dKExG58gt2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hfembedding(story):\n",
        "  # Initialize GPT-2 tokenizer and model\n",
        "  tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "  model = AutoModel.from_pretrained('gpt2')\n",
        "\n",
        "  # Tokenize the sentence\n",
        "  tokens_gpt2 = tokenizer(story, return_tensors='pt')\n",
        "\n",
        "  # Get embeddings from the model\n",
        "  with torch.no_grad():  # No need to compute gradients\n",
        "      outputs = model(**tokens_gpt2)\n",
        "\n",
        "  # The last hidden states (embeddings) for each token\n",
        "  embeddings = outputs.last_hidden_state\n",
        "\n",
        "  # Print the embeddings shape\n",
        "  print(f\"Embeddings Shape: {embeddings.shape}\")\n",
        "\n",
        "  return tokens_gpt2, embeddings"
      ],
      "metadata": {
        "id": "ocvp7RcMg-WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story_tokens, story_embeddings = hfembedding(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJpHzOV8kMgT",
        "outputId": "e6d5bd9e-44c0-4d36-f6be-6b50458836a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings Shape: torch.Size([1, 130, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrjBPJOwjQRR",
        "outputId": "b9c7dbe7-3312-4620-fb5e-90e84e27ce72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  818,   262, 46609,  6483,   286, 22917,    11,   257, 44295,  3788,\n",
              "         11949,  3706, 13308, 24241,  2402,   257, 29746,  6072,  8546,    13,\n",
              "          1881, 13197, 14434,   683,   656,   366,   464, 20920, 33765,   553,\n",
              "           257,  2935,    72, 17343,   351, 11359,  5635,    13,  2080,   465,\n",
              "          3774,    88,  1735, 24585,    11, 18971, 11013,   272,    11,   484,\n",
              "          8350,  4065,   351,   257, 14470,   286, 14733,    13,   383, 18545,\n",
              "          1752, 11511,  3902,   257,  3331, 18609,   416, 36441,   262, 26655,\n",
              "           351,   257,   347, 31777,  9280,    12,  2364,    13,  6023,   640,\n",
              "            11,   484,   973, 13308,   338, 26880,  8033,   284,  7433,   281,\n",
              "          6181, 16687,    13,  3574,  8914, 17792,   265, 40308,   284, 48329,\n",
              "          2626, 10614, 13917,    11,   383, 20920, 33765,   290, 18971, 11013,\n",
              "           272,   599,  3711,   510, 22917,   338,  4065,    12, 26594,  3715,\n",
              "           530, 12422,  6081,    12, 20286,  8855,   379,   257,   640,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-Cm5Jdi1a6",
        "outputId": "f527521c-d846-417b-bf02-cd6cb8beaeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0273, -0.1197, -0.3293,  ..., -0.2539, -0.0627, -0.0789],\n",
              "         [ 0.0327,  0.4732,  0.1902,  ...,  0.1819,  0.1084,  0.0335],\n",
              "         [-0.3184,  0.6464,  0.0334,  ...,  0.1926, -0.1431,  0.1072],\n",
              "         ...,\n",
              "         [ 0.7330, -1.3616, -0.0279,  ..., -0.0974, -0.5326, -0.3021],\n",
              "         [ 0.5776, -0.1932, -1.0823,  ...,  0.0761,  0.2241,  0.1332],\n",
              "         [-0.1336, -0.3653,  0.1091,  ...,  0.3333,  0.4482,  0.0061]]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part-of-speeches in the generated story**"
      ],
      "metadata": {
        "id": "5DqBV89-dLSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "-r2NE-aNdNKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partsofspeech(story):\n",
        "  story_tokens = nlp(story)\n",
        "  print(\"The POS for the generated story is:\\n\")\n",
        "  for token in story_tokens:\n",
        "    print(\"TEXT:\", token.text)\n",
        "    print(\"POS:\", token.pos_)\n",
        "    print(\"****\\n\")"
      ],
      "metadata": {
        "id": "x6tKsBqZdN5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partsofspeech(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6JKIWxze8IF",
        "outputId": "d5620a31-0cef-4da5-9835-49331485ef0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The POS for the generated story is:\n",
            "\n",
            "TEXT: In\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: the\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: bustling\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: streets\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: of\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: Mumbai\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: timid\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: software\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: engineer\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: named\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: Raj\n",
            "POS: ADV\n",
            "****\n",
            "\n",
            "TEXT: stumbled\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: upon\n",
            "POS: SCONJ\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: mystical\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: samosa\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: One\n",
            "POS: NUM\n",
            "****\n",
            "\n",
            "TEXT: bite\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: transformed\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: him\n",
            "POS: PRON\n",
            "****\n",
            "\n",
            "TEXT: into\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: \"\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: The\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: Curry\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: Crusader\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: \"\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: Desi\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: superhero\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: with\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: extraordinary\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: powers\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: With\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: his\n",
            "POS: PRON\n",
            "****\n",
            "\n",
            "TEXT: trusty\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: sidekick\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: Butter\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: Naan\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: they\n",
            "POS: PRON\n",
            "****\n",
            "\n",
            "TEXT: fought\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: crime\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: with\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: dash\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: of\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: humor\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: The\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: duo\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: once\n",
            "POS: ADV\n",
            "****\n",
            "\n",
            "TEXT: foiled\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: bank\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: robbery\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: by\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: distracting\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: the\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: thieves\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: with\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: Bollywood\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: dance\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: -\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: off\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: Another\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: time\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: they\n",
            "POS: PRON\n",
            "****\n",
            "\n",
            "TEXT: used\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: Raj\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: 's\n",
            "POS: PART\n",
            "****\n",
            "\n",
            "TEXT: spicy\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: breath\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: to\n",
            "POS: PART\n",
            "****\n",
            "\n",
            "TEXT: defeat\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: an\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: evil\n",
            "POS: ADJ\n",
            "****\n",
            "\n",
            "TEXT: villain\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: From\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: saving\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: chaat\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: stalls\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: to\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: rescuing\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: lost\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: wedding\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: rings\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: ,\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: The\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: Curry\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: Crusader\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: and\n",
            "POS: CCONJ\n",
            "****\n",
            "\n",
            "TEXT: Butter\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: Naan\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: spiced\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: up\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: Mumbai\n",
            "POS: PROPN\n",
            "****\n",
            "\n",
            "TEXT: 's\n",
            "POS: PART\n",
            "****\n",
            "\n",
            "TEXT: crime\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: -\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: fighting\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: scene\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: one\n",
            "POS: NUM\n",
            "****\n",
            "\n",
            "TEXT: masala\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: -\n",
            "POS: PUNCT\n",
            "****\n",
            "\n",
            "TEXT: filled\n",
            "POS: VERB\n",
            "****\n",
            "\n",
            "TEXT: adventure\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: at\n",
            "POS: ADP\n",
            "****\n",
            "\n",
            "TEXT: a\n",
            "POS: DET\n",
            "****\n",
            "\n",
            "TEXT: time\n",
            "POS: NOUN\n",
            "****\n",
            "\n",
            "TEXT: .\n",
            "POS: PUNCT\n",
            "****\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acZTB1YfggLl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}