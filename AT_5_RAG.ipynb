{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd31307-34c6-4e43-9df4-24518b035540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\nydata-profiling 4.2.0 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.2.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.10.3 which is incompatible.\ntensorflow-cpu 2.14.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\ntensorboard-plugin-profile 2.14.0 requires protobuf<5.0.0dev,>=3.19.6, but you have protobuf 5.29.1 which is incompatible.\nnumba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.4 which is incompatible.\nmlflow-skinny 2.9.2 requires importlib-metadata!=4.7.0,<8,>=3.7.0, but you have importlib-metadata 8.5.0 which is incompatible.\nmlflow-skinny 2.9.2 requires protobuf<5,>=3.12.0, but you have protobuf 5.29.1 which is incompatible.\ngoogle-api-core 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.29.1 which is incompatible.\ndatabricks-feature-engineering 0.2.1 requires protobuf<5,>=3.12.0, but you have protobuf 5.29.1 which is incompatible.\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain-community langchain-huggingface langchain-chroma faiss-cpu pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "384fd5d9-bf3f-4ec7-9685-89876c42541c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0df34c9-6f9d-493d-88b6-11f1552643d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from getpass import getpass\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc03011d-aa68-4a49-bafe-49c4f265904d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       " [REDACTED]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c54d052-0274-45b4-8de5-318754ff0f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file_loc: str) -> List[Document]:\n",
    "    try:\n",
    "        \"\"\"Load data into a list of Documents\n",
    "        Args:\n",
    "            file_type: the type of file to load\n",
    "        Returns:    list of Documents\n",
    "        \"\"\"\n",
    "        loader = PyPDFLoader(file_loc)\n",
    "        data = loader.load()\n",
    "\n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise SystemExit(f\"Exiting due to the error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f28610c-7db5-413e-bc58-7c677f6cc097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_chunk(data: list) -> List[Document]:\n",
    "    \"\"\"Prepare Chunks\n",
    "    Args:\n",
    "        data: list of Documents\n",
    "    Returns: list of Chunks\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=100, chunk_overlap=10, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        documents = text_splitter.split_documents(data)\n",
    "\n",
    "        return documents, len(documents)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise SystemExit(f\"Exiting due to the error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070fcfdd-b11d-46a6-b3d6-0a54cc4d28c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_vstores(documents: list, faiss, docstore):\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "        print(\"****Loading to Vectorstore, Please wait...****\")\n",
    "        print(f\"Adding {len(documents)} to FAISS Local\")\n",
    "\n",
    "        embeddings = HuggingFaceEmbeddings()\n",
    "        embedded_docs = embeddings.embed_documents([doc.page_content for doc in documents])\n",
    "        index = faiss.IndexFlatL2(len(embedded_docs[0]))\n",
    "        vector_stores = FAISS(\n",
    "                embedding_function=embeddings,\n",
    "                index=index,\n",
    "                docstore= InMemoryDocstore(),\n",
    "                index_to_docstore_id={},\n",
    "                )\n",
    "        vector_stores.add_documents(documents=documents, ids=[i for i in range (1, len(documents)+1)])\n",
    "        print(\"****Loading to Vectorstore, Done!****\")\n",
    "\n",
    "        vector_stores.save_local(\"online_guide_index\")\n",
    "\n",
    "        return vector_stores\n",
    "\n",
    "    except Exception as e:\n",
    "        raise SystemExit(f\"Exiting due to the error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af6aaeaa-6213-4d23-bab7-068a52bcd109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_llm(model_name: str, user_question: str, session_id: str, vstore_connection):\n",
    "    try:\n",
    "        print(f\"****Setting up {model_name}, Please wait...****\")\n",
    "        model = HuggingFaceEndpoint(\n",
    "                        repo_id=model_name,\n",
    "                        task=\"text-generation\",\n",
    "                        max_new_tokens=512,\n",
    "                        top_k=10,\n",
    "                        top_p=0.95,\n",
    "                        temperature=0.01,\n",
    "                        do_sample=False,\n",
    "                        repetition_penalty=1.03,\n",
    "                    )\n",
    "        \n",
    "        print(\"****Connecting to VectorStore****\")\n",
    "        retriever = vstore_connection.as_retriever()\n",
    "\n",
    "        print(\"****Setting up RAG Prompt****\")\n",
    "        context_system_prompt = \"\"\"Answer any user questions, If you don't know the answer, just say that you don't know. \n",
    "                    Use three sentences maximum and keep the answer concise.\"\"\"\n",
    "                                \n",
    "        context_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\",context_system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        context_retriever = create_history_aware_retriever(llm=model, retriever=retriever, prompt=context_prompt)\n",
    "\n",
    "        conversation_system_prompt = \"\"\"Answer any user questions based solely on the context below:<context>\\n\\n{context}</context>\n",
    "                    If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\"\"\"\n",
    "        \n",
    "        conversation_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\",conversation_system_prompt),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"****Building the Chains with Chat History****\")\n",
    "        context_chain = create_stuff_documents_chain(model,conversation_prompt)\n",
    "\n",
    "        rag_chain = create_retrieval_chain(context_retriever,context_chain)\n",
    "\n",
    "        store = {}\n",
    "\n",
    "        def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "            if session_id not in store:\n",
    "                store[session_id] = ChatMessageHistory()\n",
    "            return store[session_id]\n",
    "\n",
    "\n",
    "        conversational_rag_chain = RunnableWithMessageHistory(\n",
    "            rag_chain,\n",
    "            get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"answer\",\n",
    "        )\n",
    "        \n",
    "        print(\"****Invoking the Chain with User Question****\")\n",
    "        return conversational_rag_chain.invoke(\n",
    "            {\"input\": user_question},\n",
    "            config={\"configurable\": {\"session_id\": session_id}},\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        raise SystemExit(f\"Exiting due to the error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a214809d-8f5d-43b8-92bd-a3a4355ddaa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Loading to Vectorstore, Please wait...****\nAdding 2 to FAISS Local\n****Loading to Vectorstore, Done!****\n"
     ]
    }
   ],
   "source": [
    "# Function calls to create the vector store\n",
    "data = load_data(\"/dbfs/mnt/data/input_data/How_to_Buy_Products_Online_1.pdf\")\n",
    "documents, length = prepare_chunk(data)\n",
    "vc = create_vstores(documents, faiss, docstore=InMemoryDocstore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4177605-04b5-4989-a419-00d581e7627d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Setting up microsoft/Phi-3-mini-4k-instruct, Please wait...****\n****Connecting to VectorStore****\n****Setting up RAG Prompt****\n****Building the Chains with Chat History****\n****Invoking the Chain with User Question****\nQuestion: How to create an account, where I can buy products?\nAnswer: To create an account on an e-commerce website, follow these steps:\n\n1. Choose your preferred platform (e.g., Amazon, eBay, Walmart).\n2. Sign up by providing your email address and creating a secure password.\n3. Enter personal information such as your name and shipping address accurately.\n4. You can now browse products, add them to your cart, and proceed to checkout to make purchases.\n"
     ]
    }
   ],
   "source": [
    "data = run_llm(\"microsoft/Phi-3-mini-4k-instruct\", \"How to create an account, where I can buy products?\", \"uid1\", vc)\n",
    "\n",
    "# Extract the latest question\n",
    "latest_question = data['input']\n",
    "\n",
    "# Extract the latest answer\n",
    "conversation = data['answer']\n",
    "latest_answer = conversation.strip().split(\"Assistant:\")[-1].strip()\n",
    "\n",
    "print(\"Question:\", latest_question, end='\\n')\n",
    "print(\"Answer:\", latest_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1947a0cf-7474-4255-b458-2fa9a64c04f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AT_5_RAG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
